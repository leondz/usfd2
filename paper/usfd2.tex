\documentclass[11pt]{article}
\usepackage{acl2010}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\title{USFD2: Tagging Temporal Expresions and TLINKs for TempEval-2}

\author{Leon Derczynski\\
  Dept of Computer Science\\ 
  University of Sheffield\\ 
  Regent Court\\
  211 Portobello\\ 
  Sheffield S1 4DP, UK\\ 
  {\tt leon@dcs.shef.ac.uk} \And
  Robert Gaizauskas\\
  Dept of Computer Science\\
  University of Sheffield\\
  Regent Court\\
  211 Portobello\\
  Sheffield S1 4DP, UK\\
  {\tt robertg@dcs.shef.ac.uk}
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We describe the University of Sheffield system used in the TempEval-2 task, USFD2, which is a successor to USFD~\cite{hepple2007usfd}. This task focuses on identifying temporal entities and relations in text, in an attempt to further research in the field of temporal information extraction and the processing of temporal information in NLP. USFD2 identifies and anchors temporal expressions, and also attemps two of the four temporal relation assignment subtasks. A rule-based system discriminates and anchors temporal expressions, and a maxium entropy classifier assigns temporal link labels, including features describing temporal signal words in nearby text. USFD2 identified temporal expressions well, and correctly classified their type in 90\% of cases. Determining the relation between an event and time expression in the same sentence was performed at 63\% accuracy, the second highest score in this subtask.
\end{abstract}

\section{Introduction}
TempEval-2~\cite{pustejovsky2009semeval} proposes six subtasks. Our system tackles three of these: task A (identifying time expressions, assigning {\tt TIMEX3} attribute values, and anchoring them); task C (determining the temporal relation between and event and time in the same sentence); and task E (determinig the temporal relation between two main events in consecutive sentences). For our participation in the task, we have decided to employ both rule and ML-classifier based approaches. Temporal expressions are dealt with solely by rules, and relation labelling performed by NLTK's\footnote{See http://www.nltk.org/} maximum entropy classifier with rule-based processing applied during feature generation. The features included all attributes included in the TempEval-2 training data annotation, augmented by features that can be directly derived from the annotated texts. There were two main aims of this work; to create a rule-based temporal expression annotator that included knowledge from work published since GUTime~\cite{mani2000robust} and measure its performance, and to measure the performance of a classifier that includes features based on temporal signals.

In the rest of this paper, we will describe how USFD2 is constructed (Section~\ref{description}), and then go on to discuss its performance and the impact of some internal parameters on overall performance. Regarding classifiers, we found that despite using identical feature sets across relation classification tasks, performance varied significantly, and that performance trends with TempEval-2 did not match those seen when classifiers were trained on other data while performing a similar task. The paper closes with comments about future work.


\section{System Description}
\label{description}
The TempEval-2 training and test data is partitioned into data for entity recognition \& description, and data for temporal relation classification. We will first discuss our approach for temporal expression recognition, description and anchoring, and then discuss our approach to two of the relation labelling tasks.

\subsection{Identifying, describing and anchoring temporal expressions}
\label{timex}
Task A of TempEval-2 requires the identification of temporal expressions by describing a start and end bound for each expression, and assigning an ID. After this, systems should attempt to describe a {\tt TIMEX3}~\cite{ISO08} for the temporal expression, and also provide a calendrical reference for {\tt DATE}-type expressions, or a formalised period for {\tt DURATION}-type expressions.

Our timex recogniser works by building a set of n-grams (with n is 1, 2, 3, 4 or 5) from the data to be annotated, and comparing each n-gram against a hand-crafted set of regular expressions. This approach has been shown to achieve high precision, with recall increasing alongside ruleset complexity~\cite{han2006language,mani2000robust,ahn2005towards}. We choose the largest possible sequence of words that could be a single temporal expression, discarding any sub-parts that independently match any of our set of regular expressions. The result is a set of boundary-pairs that describe temporal expression locations within documents. This part of the system achieved 0.84 precision and 0.79 recall, for a balanced f1-measure of 0.82.

The next part of the task is to assign a type to each temporal expression (or {\bf timex}). These can be one of {\tt TIME}, {\tt DATE}, {\tt DURATION}, or {\tt SET}. USFD2 only distinguishes between {\tt DATE} and {\tt DURATION} timexes. If the words {\emph for} or {\emph during} occur in the three words before the timex, the timex ends with an {\emph s} (such as in ``seven years"), or the timex is a bi-gram whose first token is {\emph a} (``a month"), then the timex is deemed to be of type {\tt DURATION}; otherwise it is a {\tt DATE}. These three rules for determining type were made based on observation of output over the test data and is correct 90\% of the time with the evaluation data.

The final part of task A is to provide a value for the timex. As we only annotate {\tt DATE}s and {\tt DURATION}s, these will be either a fixed calendrical reference in the format YYYY-MM-DD, or a duration in according to the TIMEX2 standard~\cite{ferro2005tides}. Timex strings of \emph{today} or \emph{now} were assigned the special value {\tt PRESENT\_REF}, which assumes that {\emph today} is being used in a literal ans not figurative manner, an assumption which holds around 90\% of the time~\cite{ahn2005towards} in newswire text such as that provided for TempEval-2. USFD-2 will then check to see if numeric words are in the timex, in an effort to calculate a temporal distance from the document creation time (DCT), as well as words like \emph{last} or \emph{next}. This distance figure supplies either the second parameter to a {\tt DURATION} value, or helps calculate DCT offset. Vague strings such as \emph{few} are represented in duration values with an {\tt X}. We next search the timex for temporal unit strings (e.g. \emph{quarter}, \emph{day}). This helps build either a duration length or an offset. If we are anchoring a date, the offset is applied to DCT, and date granularity adjusted according to the coarsest temporal primitive present -- for example, if DCT is 1997-06-12 and our timex is \emph{six months ago}, a value of 1997-01 is assigned, as there is little chance that the temporal expression refers to the day precisely six months ago.

Where weekday names are found, we used Baldwin's 7-day window~\cite{baldwin2002learning} to anchor these to a calendrical timeline. This technique has been found to be accurate over 94\% of the time with newswire text~\cite{mazur2008s}. Where dates are found that do not specify a year or a clear temporal direction marker (e.g., {\emph April 17} vs. \emph{last July}), our algorithm counts the number of days between DCT and the next occurence of that date. If this is over a limit $f$, then the date is assumed to be last year. This is a very general rule and does not take into account the tendency of very-precisely-described dates to be closer to DCT, and far off dates to be loosely specified. An $f$-value of 14 days gives the highest performance.

Anchoring dates / specifying duration lengths was the most complex part of task A and our na\"{\i}ve rule set was correct only 17\% of the time.

\subsection{Labelling temporal relations}
\label{tlink} 

signals picked from timebank

e1-signal-e2 'rule' db, partially reproduce

signal assoc window

per entity signal assoc - what approaches would be better? does cheng thesis tackle this?

\section{Discussion}
\label{discussion}

ease of coding

good performance with rule-based element, even decent recall levels

a hit/miss metric for timex values gives partial matches a zero score

E-E worse than E-T here, but E-E better than E-T in mltr paper / esslli signals paper

simple system can perform well with some tasks

compare signal approach with min paper from tempeval 2007

performance classifier based approaches seem to be levelling off for relation classification - mltr; esslli; markov nets; overall results still in 0.5-0.7 range

\section{Conclusion}
\label{conclusion}

\section*{Acknowledgments}
The first author would like to acknowledge the UK Engineering and Physical Science Research Council for support in the form of a doctoral studentship.

\bibliographystyle{acl}
\bibliography{usfd2}


\end{document}

